# Introduction
This repo serves as an introductory resource and guide for those interested in deploying LLM solutions on ROCm. It covers a high level discussion on the foundation of LLMs and includes practical implementations and slides users can follow along.

# Target Audience
- Programmers familiar with Python
- Computer Science or Electrical Engineering students interested in building LLM solutions on ROCm
- Anyone looking to build their first LLM project

# Included Materials
- Setting up your ROCm environment
- LLM inferencing using transformers
- Inferencing and setting up your LLM service using ollama
- Fine tuning your model with custom dataset(s) to perform function calling
- Function calling integration
- Lecture slide
